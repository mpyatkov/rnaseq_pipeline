#!/bin/bash -l

set -o errexit
set -o pipefail
set -o nounset

##################################################################################
# Max Pyatkov, 25.01.2021
##################################################################################
# Specify which shell to use
#$ -S /bin/bash
#$ -cwd
#$ -pe omp 16
#$ -j y
#$ -e ./logs/
#$ -o ./logs/
#$ -l scratch_free=200G
#$ -l mem_per_core=4G
##################################################################################

# export all variables from Pipeline_Setup.conf
eval "$(../00_Setup_Pipeline/01_Pipeline_Setup.py --export)"

set +eu
module load miniconda
conda activate --stack ${CONDA_DIR}/samtools
conda activate --stack ${CONDA_DIR}/star
set -eu

if [ $# -ne 1 ] ; then
      echo "Need 1 arguments for the qsub command:"
      echo "qsub -N ${job_name}'_'${sample_id} -P wax-dk -l h_rt=${TIME_LIMIT} TopHat_Paired_End.qsub ${sample_id}"
      exit 0
fi

#process the command line arguments
SAMPLE_ID=$1

#Print variables (make sure they appear correctly):
echo "-----------------------"
echo "Start of variable list:"
echo "-----------------------"
echo "SAMPLE_ID: ${SAMPLE_ID}"
echo "Dataset_DIR: ${DATASET_DIR}"
echo "End of variable list"
echo "-----------------------"

start_time=$(date +"%s")

# Now let's keep track of some information just in case anything goes wrong
echo "=========================================================="
echo "Starting on : $(date)"
echo "Running on node : $(hostname)"
echo "Current directory : $(pwd)"
echo "Current job ID : $JOB_ID"
echo "Current job name : $JOB_NAME"
echo "Task index number : $SGE_TASK_ID"
echo "Parameter for multiple cores : $NSLOTS"
echo "=========================================================="

# Go to local scratch directory
echo "Change dir to scratch directory"

cd "${TMPDIR}"

echo "Print scratch directory location: ${TMPDIR}"

# get correct reads
function get_fastq_by_read_number(){
    local READ_NUMBER=$1
    R=$(find ${DATASET_DIR}/${SAMPLE_ID} \( -name "*_${READ_NUMBER}.f*q.gz" -o -name "*R${READ_NUMBER}*.f*q.gz" \) | head -n1)
    echo $R
}

R1=$(get_fastq_by_read_number 1)
R2=$(get_fastq_by_read_number 2)

# if fastq files do not exist the following commands should raise
# an error and script will be interrupted
for f in $R1; do
    [ -e "$f" ] && echo "R1 file $f exists" || (echo "ERROR: R1 file $f does not exist"; exit 1)
done

for f in $R2; do
    [ -e "$f" ] && echo "R2 file $f exists" || (echo "ERROR: R2 file $f does not exist"; exit 1) 
done

# copy user input data files to scratch
# copy R1 to TMPDIR
cp $R1 .
# copy R2 to TMPDIR
cp $R2 .

# left_list=$(find . -name "*_1*.f*q.gz" | xargs -n1 basename | paste -s -d ",")
# right_list=$(find . -name "*_2*.f*q.gz" | xargs -n1 basename | paste -s -d ",")

left_list=$(basename $R1)
right_list=$(basename $R2)

echo "left_list: ${left_list}"
echo "right_list: ${right_list}"

#Make output dir:
storage_dir="${DATASET_DIR}/${SAMPLE_ID}"
output_dir="${TMPDIR}/aligner"
mkdir -p "${output_dir}"

echo 'List files in the scratch directory:'

ls -alh

echo 'Starting STAR'

(set -x; \
 STAR --runThreadN ${NSLOTS} \
      --genomeDir ${STARINDEX_DIR} \
      --readFilesCommand gunzip -c \
      --readFilesIn ${left_list} ${right_list} \
      --outSAMtype BAM SortedByCoordinate \
      --outFileNamePrefix ./"${SAMPLE_ID}_"
)
echo 'Ending STAR'

# by default STAR create file with name Aligned.sortedByCoord.out.bam
# if we added the prefix than the name will be
# PREFIX_Aligned.sortedByCoord.out.bam
ls -l

IN="${SAMPLE_ID}_Aligned.sortedByCoord.out.bam"
mv ${IN} ${output_dir}
mv *final.out ${output_dir}

echo 'Starting samtools commands'

# Filter out all the read records that are not primary alignment
# Otherwords: extract all primary alignment reads
samtools view -@ ${NSLOTS} -F 0x100 -b ${output_dir}/${IN} > ${output_dir}/primary.bam

# Generate index for a bam file
samtools index -@ ${NSLOTS} ${output_dir}/${IN}
samtools index -@ ${NSLOTS} ${output_dir}/primary.bam

# Collect statistics for a bam file
samtools flagstat -@ ${NSLOTS} ${output_dir}/primary.bam > ${output_dir}/statistics_for_primary_reads.txt
samtools flagstat -@ ${NSLOTS} ${output_dir}/${IN} > ${output_dir}/statistics_for_all_accepted_reads.txt

# numunique_hits.txt contains the mapping statistics of all mappable reads,
# ***excluding*** multi-mappable reads (identical to b)). This is not applicable
# for paired-end reads.
samtools view ${output_dir}/${IN} | cut -f 1 | sort | uniq | wc -l > numunique_hits.txt

# We now want to get the uniquely mapped reads:
pushd "${output_dir}"

samtools view -q 255 -@ {NSLOTS} -b "primary.bam" > "primary_unique.bam"
samtools index "primary_unique.bam"

#Collect statistics for a bam file
samtools flagstat "primary_unique.bam" > "statistics_for_primary_unique_reads.txt"

popd

echo 'Ending samtools commands'


# ---------------------------------------------------------------------------------
##################################################################################
# remove stuff that we dont need

# For DESeq, we need the primary_unique.bam
rm ${output_dir}/${IN}
rm ${output_dir}/${IN}.bai
rm ${output_dir}/primary.bam
rm ${output_dir}/primary.bam.bai

# Rename the output files
output_list=${output_dir}/*
for output_file in ${output_list}
do
    output_file_name=$(basename $output_file)
    
    #Add the ${SAMPLE_ID} as a file name prefix
    mv "${output_dir}/$output_file_name" "${output_dir}/${SAMPLE_ID}_${output_file_name}"
done

echo 'Starting spliced_read_counts'

#cd into the ${output_dir}
pushd "${output_dir}"
######################

output_file=$output_dir/${SAMPLE_ID}'_spliced_read_counts.txt'
rm -rf ${output_file} && touch ${output_file}

# It would be useful to know the number of mapped reads that have skipped regions
# from the reference genome
# This information is in the CIGAR string
# http://zenfractal.com/2013/06/19/playing-with-matches/
# Aligned reads in a SAM or BAM file typically have a Compact Idiosyncratic
# Gapped Alignment Report (CIGAR) string that expresses how the read is mapped to
# the reference genome.
# The CIGAR string is in the 6th column:
# https://samtools.github.io/hts-specs/SAMv1.pdf
# M stands for: alignment match (can be a sequence match or mismatch)
# N stands for: skipped region from the reference
skipped_reads=$(samtools view "${SAMPLE_ID}_primary_unique.bam" | awk '($6 ~ /N/)' | cut -f6 | wc -l)

#Need a regular expression to specifically find these spliced reads:
#Bunch of numbers then "M", bunch of numbers then "N", bunch of numbers then "M":
spliced_reads=$(samtools view "${SAMPLE_ID}_primary_unique.bam" | awk '($6 ~ /[0-9]+[M][0-9]+[N][0-9]+[M]/)' | cut -f6 | wc -l )

#Print header to output file:
printf "SAMPLE_ID\tskipped_region_READS\tsplice_junction_READS\n" >> "${output_file}"

#Print to output file
printf "%s\t%s\t%s\t\n" "${SAMPLE_ID}" "${skipped_reads}" "${spliced_reads}" >> "${output_file}"

#cd out of ${output_dir}
popd

echo 'Ending spliced_read_counts'

# copy the output files to users storage dir
cp *.txt ${output_dir}
cp -r ${output_dir} ${storage_dir}

echo "List files in scratch"
ls -alh

echo "=========================================================="
echo "Finished on : $(date)"

#Use to calculate job time:
#End_Time in seconds
end_time=$(date +"%s")
diff=$((end_time-start_time))
echo "$((diff / 3600)) hours, $(((diff / 60) % 60)) minutes and $((diff % 60)) seconds elapsed."
echo "=========================================================="
# special sign to show that execution is finished (do not remove)
echo "IAMOK"
