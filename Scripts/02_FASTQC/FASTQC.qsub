#!/bin/bash -l

set -o errexit
set -o pipefail
set -o nounset

##################################################################################
#Andy Rampersaud, 02.23.16
#This script is called by fastqC.sh
##################################################################################
# Specify which shell to use
#$ -S /bin/bash
# current working directory option
#$ -cwd
# 
#$ -j y
#$ -e ./logs/
#$ -o ./logs/
#$ -l scratch_free=200G
##################################################################################
#Initialize variables from fastqC.sh
##################################################################################

# export all variables from Pipeline_Setup.conf
eval "$(../00_Setup_Pipeline/01_Pipeline_Setup.py --export)"

#checking the command line arg
#-ne : "is not equal to"

if [ $# -ne 2 ] ; then
      echo "Need 2 arguments for the qsub command:"
      echo "qsub -N ${job_name}_${sample_id} -P ${PROJECT} -l h_rt=${TIME_LIMIT} FASTQC.qsub ${sample_id} ${output_dir}"
      exit 1
fi

#process the command line arguments
sample_id=$1
output_dir=$2

# Now let's keep track of some information just in case anything goes wrong
echo "=========================================================="
#Use to calculate job time:
#Start_Time in seconds
start_time=$(date +"%s")
echo "Starting on : $(date)"
echo "Running on node : $(hostname)"
echo "Current directory : $(pwd)"
echo "Current job ID : $JOB_ID"
echo "Current job name : $JOB_NAME"
echo "Task index number : $SGE_TASK_ID"
echo "Parameter for multiple cores : $NSLOTS"
echo "=========================================================="

# Go to local scratch directory

printf "\nChange dir to scratch directory\n"
cd ${TMPDIR}
printf "\nPrint scratch directory location: ${TMPDIR}"
printf "\nLoading required modules...\n"

set +eu
module load miniconda
conda activate --stack ${CONDA_DIR}/fastqc
set -eu

# module load fastqc

# copy user input data files to scratch
# Copy over the *R1*.fq.gz file(s):
cp ${DATASET_DIR}/${sample_id}/*_1*.f*q.gz .

# Copy over the *R2*.fq.gz file(s):
cp ${DATASET_DIR}/${sample_id}/*_2*.f*q.gz .

# Create FASTQC output folder to store files:
fastqc_dir="${sample_id}_FASTQC"
mkdir -p "${fastqc_dir}"

printf "\nList files in scratch directory:\n"
ls -alh
printf "\nStarting to run my commands\n"
printf "Unzip files:"

time gzip -d *.gz

printf "\nFinished unzipping\n"
printf "\nPrint first 20 lines of fastq file:\n"

head -20 *.f*q


printf "\nStarting 03_Read_Length command\n"

## Former step 03_Read_length start
# create output file
output_file="${output_dir}/${sample_id}_read_length.txt"
rm -rf "${output_file}" && touch "${output_file}"

#-----------------------------------------------------------------------------------
# awk Command Explanation:
# http://www.biostars.org/p/72433/
# For every 2nd line in group of 4 lines (NR%4 == 2):
# Count the number of characters in the read sequence (length($0))
# Store that count in the array (lengths)
# Record the frequency of distinct counts in array (lengths) ({lengths[length($0)]++})
# End the loop (END)
# Print the output:
# For each element (L) in array (lengths) (for (L in lengths))
# Print the element (L), tab, frequency of (L) ({print L "\t" lengths[L]})
# Input file: sample.fastq, Output file: Read_Length.txt
# Alternate explanation:
# It reads like this: every second line in every group of 4 lines (the sequence
# line), measure the length of the sequence and increment the array cell
# corresponding to that length. When all lines have been read, loop over the array
# to print its content. In awk, arrays and array cells are initialized when they
# are called for the first time, no need to initialize them before.
#-----------------------------------------------------------------------------------

# run this awk command for each fastq file:
fastq_list=*.f*q
for fastq_file in ${fastq_list}
do
    echo
    echo "Processing "${fastq_file}
    echo

    #Need a "-v" for every variable
    awk -v sample_id=${sample_id} -v fastq_file=${fastq_file} 'NR%4 == 2 {lengths[length($0)]++} END {for (L in lengths) {print sample_id "\t" fastq_file "\t" L "\t" lengths[L]}}' ${fastq_file} >> $output_file
done
# step 03_Read_Length end

printf "\nend 03_Read_Length command\n"


printf "\nStarting fastqC command\n"

# Run the command for each fastq file:
fastq_list=*.f*q
for fastq_file in ${fastq_list}
do
    printf "fastqc --outdir %s %s" "${fastqc_dir}" "${fastq_file}"

    fastqc --outdir ${fastqc_dir} ${fastq_file}
done
#--------------------------------------------------------------------------------
printf '\nFinished FASTQC command\n'
printf '\nCopy output to storage dir\n'

cp -r $fastqc_dir $output_dir

printf "\nList files in scratch\n"
ls -alh

echo "Finished on : $(date)"

#Use to calculate job time:
#End_Time in seconds
end_time=$(date +"%s")
diff=$((end_time-start_time))
echo "$((diff / 3600)) hours, $(((diff / 60) % 60)) minutes and $((diff % 60)) seconds elapsed."
echo "=========================================================="
echo "IAMOK"
